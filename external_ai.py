# src/ai_integration/external_ai.py
from __future__ import annotations

import requests
import json
from typing import Dict, Any, List, Optional
import logging
from datetime import datetime
import os
import time

logger = logging.getLogger(__name__)

class AIAnalysisService:
    """
    –°–µ—Ä–≤–∏—Å –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –≤–Ω–µ—à–Ω–∏–º–∏ –ò–ò API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä—ã–Ω–∫–∞
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç OpenAI, Anthropic Claude, Google Gemini
    """

    def __init__(self):
        self.services = {
            'openai': OpenAIAnalyzer(),
            'claude': ClaudeAnalyzer(),
            'gemini': GeminiAnalyzer(),
            'local_llm': LocalLLMAnalyzer()  # –î–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        }

    def analyze_market_sentiment(self, news_texts: List[str], 
                                service: str = 'openai') -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π —Ä—ã–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤–æ—Å—Ç–µ–π

        Args:
            news_texts: –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
            service: –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –ò–ò —Å–µ—Ä–≤–∏—Å

        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π
        """
        if service not in self.services:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Å–µ—Ä–≤–∏—Å: {service}")

        return self.services[service].analyze_sentiment(news_texts)

    def generate_trading_insights(self, market_data: Dict[str, Any],
                                 service: str = 'openai') -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        """
        if service not in self.services:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Å–µ—Ä–≤–∏—Å: {service}")

        return self.services[service].generate_insights(market_data)

    def explain_prediction(self, prediction_data: Dict[str, Any],
                          service: str = 'openai') -> str:
        """
        –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞ –≤ –ø–æ–Ω—è—Ç–Ω–æ–π —Ñ–æ—Ä–º–µ
        """
        if service not in self.services:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Å–µ—Ä–≤–∏—Å: {service}")

        return self.services[service].explain_prediction(prediction_data)


class OpenAIAnalyzer:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å OpenAI GPT"""

    def __init__(self):
        self.api_key = os.getenv('OPENAI_API_KEY')
        self.base_url = "https://api.openai.com/v1"
        self.model = "gpt-4-turbo-preview"

    def analyze_sentiment(self, news_texts: List[str]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π —á–µ—Ä–µ–∑ OpenAI"""
        if not self.api_key:
            logger.error("‚ùå OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return {'error': 'API key –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'}

        try:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            combined_text = "\n".join(news_texts[:10])  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ

            prompt = f"""
            –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –≤ —Å–ª–µ–¥—É—é—â–∏—Ö —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç—è—Ö –∏ –¥–∞–π –æ—Ü–µ–Ω–∫—É –≤–ª–∏—è–Ω–∏—è –Ω–∞ —Ä—ã–Ω–æ–∫:

            –ù–û–í–û–°–¢–ò:
            {combined_text}

            –û—Ü–µ–Ω–∏ –ø–æ —à–∫–∞–ª–µ –æ—Ç -100 –¥–æ +100:
            - –û–±—â–µ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ (-100 = –æ—á–µ–Ω—å –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ, +100 = –æ—á–µ–Ω—å –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–µ)
            - –í–ª–∏—è–Ω–∏–µ –Ω–∞ –∞–∫—Ü–∏–∏ (-100 = —Å–∏–ª—å–Ω–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ, +100 = —Å–∏–ª—å–Ω–æ –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–µ)
            - –í–ª–∏—è–Ω–∏–µ –Ω–∞ –≤–∞–ª—é—Ç–Ω—ã–π —Ä—ã–Ω–æ–∫
            - –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–æ–µ –≤–ª–∏—è–Ω–∏–µ (1-7 –¥–Ω–µ–π)
            - –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–µ –≤–ª–∏—è–Ω–∏–µ (1-3 –º–µ—Å—è—Ü–∞)

            –û—Ç–≤–µ—Ç—å –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
            {{
                "overall_sentiment": —á–∏—Å–ª–æ,
                "stock_impact": —á–∏—Å–ª–æ,
                "currency_impact": —á–∏—Å–ª–æ,
                "short_term_impact": —á–∏—Å–ª–æ,
                "long_term_impact": —á–∏—Å–ª–æ,
                "key_themes": ["—Ç–µ–º–∞1", "—Ç–µ–º–∞2"],
                "summary": "–∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ"
            }}
            """

            response = self._make_request(prompt)

            # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
            try:
                result = json.loads(response)
                result['timestamp'] = datetime.now().isoformat()
                result['source'] = 'openai'
                return result
            except json.JSONDecodeError:
                logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –æ—Ç–≤–µ—Ç")
                return {
                    'overall_sentiment': 0,
                    'summary': response[:500],
                    'source': 'openai',
                    'timestamp': datetime.now().isoformat()
                }

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π OpenAI: {e}")
            return {'error': str(e)}

    def generate_insights(self, market_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤"""
        try:
            prompt = f"""
            –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–µ —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –¥–∞–π —Ç–æ—Ä–≥–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:

            –î–ê–ù–ù–´–ï:
            {json.dumps(market_data, indent=2, ensure_ascii=False)}

            –î–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
            {{
                "recommendation": "BUY/SELL/HOLD",
                "confidence": 0.0-1.0,
                "reasoning": "–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ",
                "risk_level": "LOW/MEDIUM/HIGH",
                "time_horizon": "SHORT/MEDIUM/LONG",
                "key_factors": ["—Ñ–∞–∫—Ç–æ—Ä1", "—Ñ–∞–∫—Ç–æ—Ä2"],
                "price_target": —á–∏—Å–ª–æ –∏–ª–∏ null,
                "stop_loss": —á–∏—Å–ª–æ –∏–ª–∏ null
            }}
            """

            response = self._make_request(prompt)

            try:
                result = json.loads(response)
                result['timestamp'] = datetime.now().isoformat()
                result['source'] = 'openai'
                return result
            except json.JSONDecodeError:
                return {
                    'recommendation': 'HOLD',
                    'reasoning': response[:500],
                    'source': 'openai',
                    'timestamp': datetime.now().isoformat()
                }

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–Ω—Å–∞–π—Ç–æ–≤: {e}")
            return {'error': str(e)}

    def explain_prediction(self, prediction_data: Dict[str, Any]) -> str:
        """–û–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞ –º–æ–¥–µ–ª–∏"""
        try:
            prompt = f"""
            –û–±—ä—è—Å–Ω–∏ –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞ —Ç–æ—Ä–≥–æ–≤–æ–π –º–æ–¥–µ–ª–∏:

            –î–ê–ù–ù–´–ï –ü–†–û–ì–ù–û–ó–ê:
            {json.dumps(prediction_data, indent=2, ensure_ascii=False)}

            –î–∞–π –ø–æ–Ω—è—Ç–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ:
            1. –ß—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç —ç—Ç–æ—Ç –ø—Ä–æ–≥–Ω–æ–∑
            2. –ù–∞—Å–∫–æ–ª—å–∫–æ –µ–º—É –º–æ–∂–Ω–æ –¥–æ–≤–µ—Ä—è—Ç—å
            3. –ö–∞–∫–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã –ø–æ–≤–ª–∏—è–ª–∏ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            4. –ß—Ç–æ —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç –¥–ª—è —Ç–æ—Ä–≥–æ–≤–ª–∏

            –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–Ω—è—Ç–µ–Ω –¥–∞–∂–µ –Ω–∞—á–∏–Ω–∞—é—â–µ–º—É —Ç—Ä–µ–π–¥–µ—Ä—É.
            """

            response = self._make_request(prompt)
            return response

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞: {e}")
            return f"–û—à–∏–±–∫–∞ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è: {e}"

    def _make_request(self, prompt: str) -> str:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –∫ OpenAI API"""
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }

        data = {
            'model': self.model,
            'messages': [
                {
                    'role': 'system',
                    'content': '–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–º —Ä—ã–Ω–∫–∞–º –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º—É –∞–Ω–∞–ª–∏–∑—É. –û—Ç–≤–µ—á–∞–π —Ç–æ—á–Ω–æ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ.'
                },
                {
                    'role': 'user',
                    'content': prompt
                }
            ],
            'temperature': 0.3,
            'max_tokens': 2000
        }

        response = requests.post(
            f"{self.base_url}/chat/completions",
            headers=headers,
            json=data,
            timeout=30
        )

        if response.status_code == 200:
            result = response.json()
            return result['choices'][0]['message']['content']
        else:
            raise Exception(f"OpenAI API error: {response.status_code} - {response.text}")


class ClaudeAnalyzer:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Anthropic Claude"""

    def __init__(self):
        self.api_key = os.getenv('ANTHROPIC_API_KEY')
        self.base_url = "https://api.anthropic.com/v1"
        self.model = "claude-3-sonnet-20240229"

    def analyze_sentiment(self, news_texts: List[str]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π —á–µ—Ä–µ–∑ Claude"""
        if not self.api_key:
            logger.warning("‚ö†Ô∏è ANTHROPIC_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–∞–≥–ª—É—à–∫–∞")
            return self._mock_sentiment_response()

        try:
            combined_text = "\n".join(news_texts[:10])

            prompt = f"""
            –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏ –æ—Ü–µ–Ω–∏ —Ä—ã–Ω–æ—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è:

            {combined_text}

            –î–∞–π –æ—Ü–µ–Ω–∫–∏ –æ—Ç -100 –¥–æ +100 –∏ –≤–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON:
            {{
                "overall_sentiment": —á–∏—Å–ª–æ,
                "stock_impact": —á–∏—Å–ª–æ, 
                "currency_impact": —á–∏—Å–ª–æ,
                "volatility_expectation": —á–∏—Å–ª–æ,
                "key_themes": ["—Ç–µ–º–∞1", "—Ç–µ–º–∞2"],
                "summary": "–∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ"
            }}
            """

            response = self._make_request(prompt)

            try:
                result = json.loads(response)
                result['timestamp'] = datetime.now().isoformat()
                result['source'] = 'claude'
                return result
            except json.JSONDecodeError:
                return self._mock_sentiment_response()

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ Claude API: {e}")
            return self._mock_sentiment_response()

    def generate_insights(self, market_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤ —á–µ—Ä–µ–∑ Claude"""
        # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è Claude (—Ä–µ–∞–ª—å–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–æ–≥–∏—á–Ω–∞ OpenAI)
        return {
            'recommendation': 'HOLD',
            'confidence': 0.6,
            'reasoning': '–ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Claude –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω',
            'source': 'claude',
            'timestamp': datetime.now().isoformat()
        }

    def explain_prediction(self, prediction_data: Dict[str, Any]) -> str:
        """–û–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞ —á–µ—Ä–µ–∑ Claude"""
        return "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ Claude API –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ"

    def _make_request(self, prompt: str) -> str:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –∫ Claude API"""
        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è (—Ç—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏ –ø–æ–¥ —Ä–µ–∞–ª—å–Ω—ã–π API)
        raise NotImplementedError("Claude API –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Ç—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏")

    def _mock_sentiment_response(self) -> Dict[str, Any]:
        """–ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π"""
        return {
            'overall_sentiment': 0,
            'stock_impact': 0,
            'currency_impact': 0,
            'volatility_expectation': 0,
            'key_themes': ['mock_analysis'],
            'summary': '–ó–∞–≥–ª—É—à–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π',
            'source': 'claude_mock',
            'timestamp': datetime.now().isoformat()
        }


class GeminiAnalyzer:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Google Gemini"""

    def __init__(self):
        self.api_key = os.getenv('GOOGLE_API_KEY')
        self.base_url = "https://generativelanguage.googleapis.com/v1"
        self.model = "gemini-pro"

    def analyze_sentiment(self, news_texts: List[str]) -> Dict[str, Any]:
        """–ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è Gemini"""
        return {
            'overall_sentiment': 0,
            'summary': 'Gemini –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ',
            'source': 'gemini_mock',
            'timestamp': datetime.now().isoformat()
        }

    def generate_insights(self, market_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è Gemini"""
        return {
            'recommendation': 'HOLD',
            'reasoning': 'Gemini –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ',
            'source': 'gemini_mock',
            'timestamp': datetime.now().isoformat()
        }

    def explain_prediction(self, prediction_data: Dict[str, Any]) -> str:
        """–ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è Gemini"""
        return "Gemini –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ"


class LocalLLMAnalyzer:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ LLM –º–æ–¥–µ–ª—è–º–∏"""

    def __init__(self):
        self.ollama_url = os.getenv('OLLAMA_URL', 'http://localhost:11434')
        self.model = os.getenv('LOCAL_LLM_MODEL', 'llama2')

    def analyze_sentiment(self, news_texts: List[str]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π —á–µ—Ä–µ–∑ –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Ollama
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
            if response.status_code != 200:
                raise Exception("Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

            combined_text = "\n".join(news_texts[:5])  # –ú–µ–Ω—å—à–µ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

            prompt = f"""
            –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏ –æ—Ü–µ–Ω–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è —Ä—ã–Ω–∫–∞ –æ—Ç -100 –¥–æ +100:

            {combined_text}

            –û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
            –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: [—á–∏—Å–ª–æ]
            –†–µ–∑—é–º–µ: [–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ]
            """

            response = self._make_ollama_request(prompt)

            # –ü–∞—Ä—Å–∏–º –ø—Ä–æ—Å—Ç–æ–π –æ—Ç–≤–µ—Ç
            sentiment = 0
            summary = response

            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            import re
            sentiment_match = re.search(r'–ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ:\s*([+-]?\d+)', response)
            if sentiment_match:
                sentiment = int(sentiment_match.group(1))

            return {
                'overall_sentiment': sentiment,
                'summary': summary[:200],
                'source': 'local_llm',
                'timestamp': datetime.now().isoformat()
            }

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –õ–æ–∫–∞–ª—å–Ω–∞—è LLM –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}")
            return {
                'overall_sentiment': 0,
                'summary': '–õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞',
                'source': 'local_llm_mock',
                'timestamp': datetime.now().isoformat()
            }

    def generate_insights(self, market_data: Dict[str, Any]) -> Dict[str, Any]:
        """–¢–æ—Ä–≥–æ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã —á–µ—Ä–µ–∑ –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å"""
        return {
            'recommendation': 'HOLD',
            'reasoning': '–õ–æ–∫–∞–ª—å–Ω–∞—è LLM –∞–Ω–∞–ª–∏–∑ –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ',
            'source': 'local_llm',
            'timestamp': datetime.now().isoformat()
        }

    def explain_prediction(self, prediction_data: Dict[str, Any]) -> str:
        """–û–±—ä—è—Å–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å"""
        return "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –ª–æ–∫–∞–ª—å–Ω—É—é LLM –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ"

    def _make_ollama_request(self, prompt: str) -> str:
        """–ó–∞–ø—Ä–æ—Å –∫ Ollama API"""
        data = {
            'model': self.model,
            'prompt': prompt,
            'stream': False
        }

        response = requests.post(
            f"{self.ollama_url}/api/generate",
            json=data,
            timeout=30
        )

        if response.status_code == 200:
            result = response.json()
            return result.get('response', '')
        else:
            raise Exception(f"Ollama API error: {response.status_code}")


# –ú–æ–¥—É–ª—å –¥–ª—è —Å–±–æ—Ä–∞ –Ω–æ–≤–æ—Å—Ç–µ–π
class NewsCollector:
    """–°–±–æ—Ä—â–∏–∫ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π"""

    def __init__(self):
        self.news_api_key = os.getenv('NEWS_API_KEY')
        self.alpha_vantage_key = os.getenv('ALPHA_VANTAGE_API_KEY')

    def collect_financial_news(self, query: str = 'financial markets', 
                              language: str = 'ru',
                              max_articles: int = 20) -> List[Dict[str, str]]:
        """
        –°–±–æ—Ä —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏: [{'title': '', 'content': '', 'source': '', 'timestamp': ''}]
        """
        news = []

        # NewsAPI
        if self.news_api_key:
            try:
                news.extend(self._collect_from_newsapi(query, language, max_articles // 2))
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ NewsAPI: {e}")

        # Alpha Vantage News
        if self.alpha_vantage_key:
            try:
                news.extend(self._collect_from_alpha_vantage(max_articles // 2))
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Alpha Vantage: {e}")

        # –ó–∞–≥–ª—É—à–∫–∞ —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –Ω–æ–≤–æ—Å—Ç–µ–π
        if not news:
            news = self._get_mock_news()

        return news[:max_articles]

    def _collect_from_newsapi(self, query: str, language: str, max_articles: int) -> List[Dict[str, str]]:
        """–°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ NewsAPI"""
        url = "https://newsapi.org/v2/everything"
        params = {
            'q': query,
            'language': language,
            'sortBy': 'publishedAt',
            'pageSize': max_articles,
            'apiKey': self.news_api_key
        }

        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()

        data = response.json()
        news = []

        for article in data.get('articles', []):
            news.append({
                'title': article.get('title', ''),
                'content': article.get('description', '') + ' ' + article.get('content', ''),
                'source': article.get('source', {}).get('name', 'NewsAPI'),
                'timestamp': article.get('publishedAt', ''),
                'url': article.get('url', '')
            })

        return news

    def _collect_from_alpha_vantage(self, max_articles: int) -> List[Dict[str, str]]:
        """–°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ Alpha Vantage"""
        url = "https://www.alphavantage.co/query"
        params = {
            'function': 'NEWS_SENTIMENT',
            'apikey': self.alpha_vantage_key,
            'limit': max_articles
        }

        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()

        data = response.json()
        news = []

        for article in data.get('feed', []):
            news.append({
                'title': article.get('title', ''),
                'content': article.get('summary', ''),
                'source': article.get('source', 'Alpha Vantage'),
                'timestamp': article.get('time_published', ''),
                'sentiment': article.get('overall_sentiment_label', 'Neutral')
            })

        return news

    def _get_mock_news(self) -> List[Dict[str, str]]:
        """–ó–∞–≥–ª—É—à–∫–∞ —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –Ω–æ–≤–æ—Å—Ç–µ–π"""
        return [
            {
                'title': '–†—ã–Ω–∫–∏ –∞–∫—Ü–∏–π –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Å–º–µ—à–∞–Ω–Ω—É—é –¥–∏–Ω–∞–º–∏–∫—É',
                'content': '–†–æ—Å—Å–∏–π—Å–∫–∏–π —Ñ–æ–Ω–¥–æ–≤—ã–π —Ä—ã–Ω–æ–∫ –∑–∞–≤–µ—Ä—à–∏–ª —Ç–æ—Ä–≥–∏ –≤ —Å–º–µ—à–∞–Ω–Ω–æ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–∏ –Ω–∞ —Ñ–æ–Ω–µ –∫–æ–ª–µ–±–∞–Ω–∏–π –Ω–µ—Ñ—Ç—è–Ω—ã—Ö –∫–æ—Ç–∏—Ä–æ–≤–æ–∫.',
                'source': 'Mock News',
                'timestamp': datetime.now().isoformat()
            },
            {
                'title': '–¶–ë –†–§ —Å–æ—Ö—Ä–∞–Ω–∏–ª –∫–ª—é—á–µ–≤—É—é —Å—Ç–∞–≤–∫—É',
                'content': '–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –±–∞–Ω–∫ –†–æ—Å—Å–∏–∏ —Å–æ—Ö—Ä–∞–Ω–∏–ª –∫–ª—é—á–µ–≤—É—é —Å—Ç–∞–≤–∫—É –Ω–∞ —Ç–µ–∫—É—â–µ–º —É—Ä–æ–≤–Ω–µ, —á—Ç–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞–ª–æ –æ–∂–∏–¥–∞–Ω–∏—è–º –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–≤.',
                'source': 'Mock News',
                'timestamp': datetime.now().isoformat()
            },
            {
                'title': '–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –≤–∞–ª—é—Ç–Ω–æ–≥–æ —Ä—ã–Ω–∫–∞ —Ä–∞—Å—Ç–µ—Ç',
                'content': '–ö—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –∫ —Ä—É–±–ª—é –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø–æ–≤—ã—à–µ–Ω–Ω—É—é –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –Ω–∞ —Ñ–æ–Ω–µ –≥–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–æ–π –Ω–∞–ø—Ä—è–∂–µ–Ω–Ω–æ—Å—Ç–∏.',
                'source': 'Mock News',
                'timestamp': datetime.now().isoformat()
            }
        ]


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –ò–ò
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –≤–Ω–µ—à–Ω–∏–º–∏ –ò–ò —Å–µ—Ä–≤–∏—Å–∞–º–∏")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–æ–≤
    ai_service = AIAnalysisService()
    news_collector = NewsCollector()

    # –°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π
    print("üì∞ –°–±–æ—Ä —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π...")
    news = news_collector.collect_financial_news(max_articles=5)
    print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {len(news)}")

    # –ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π
    if news:
        news_texts = [article['title'] + ' ' + article['content'] for article in news]

        print("üß† –ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π —á–µ—Ä–µ–∑ –ò–ò...")

        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã
        for service in ['openai', 'claude', 'local_llm']:
            try:
                sentiment = ai_service.analyze_market_sentiment(news_texts, service=service)
                print(f"üìä {service.upper()}: –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ={sentiment.get('overall_sentiment', 0)}")
                print(f"   –†–µ–∑—é–º–µ: {sentiment.get('summary', '–ù–µ—Ç —Ä–µ–∑—é–º–µ')[:100]}")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ {service}: {e}")

    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–Ω—Å–∞–π—Ç–æ–≤
    print("\nüí° –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤...")
    mock_data = {
        'symbol': 'SBER',
        'current_price': 250.5,
        'change_percent': 2.3,
        'volume': 1500000,
        'rsi': 65,
        'macd': 0.8
    }

    try:
        insights = ai_service.generate_trading_insights(mock_data, service='openai')
        print(f"üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {insights.get('recommendation', 'HOLD')}")
        print(f"   –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ: {insights.get('reasoning', '–ù–µ—Ç –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è')[:100]}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–Ω—Å–∞–π—Ç–æ–≤: {e}")

    print("‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
